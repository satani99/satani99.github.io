<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Decoupled DMD for Diffusion Language Models | Nikhil's blog</title>
<meta name=keywords content><meta name=description content="Decoupled DMD for Diffusion Language Models: The Spear & The Shield"><meta name=author content="Nikhil Satani"><link rel=canonical href=https://satani99.github.io/posts/decoupled-dmd-for-diffusion-language-models/><link crossorigin=anonymous href=/assets/css/stylesheet.fc220c15db4aef0318bbf30adc45d33d4d7c88deff3238b23eb255afdc472ca6.css integrity="sha256-/CIMFdtK7wMYu/MK3EXTPU18iN7/MjiyPrJVr9xHLKY=" rel="preload stylesheet" as=style><link rel=icon href=https://satani99.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://satani99.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://satani99.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://satani99.github.io/apple-touch-icon.png><link rel=mask-icon href=https://satani99.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://satani99.github.io/posts/decoupled-dmd-for-diffusion-language-models/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script><meta property="og:title" content="Decoupled DMD for Diffusion Language Models"><meta property="og:description" content="Decoupled DMD for Diffusion Language Models: The Spear & The Shield"><meta property="og:type" content="article"><meta property="og:url" content="https://satani99.github.io/posts/decoupled-dmd-for-diffusion-language-models/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2026-01-20T10:50:21+05:30"><meta property="article:modified_time" content="2026-01-20T10:50:21+05:30"><meta property="og:site_name" content="Nikhil's blog"><meta name=twitter:card content="summary"><meta name=twitter:title content="Decoupled DMD for Diffusion Language Models"><meta name=twitter:description content="Decoupled DMD for Diffusion Language Models: The Spear & The Shield"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://satani99.github.io/posts/"},{"@type":"ListItem","position":2,"name":"Decoupled DMD for Diffusion Language Models","item":"https://satani99.github.io/posts/decoupled-dmd-for-diffusion-language-models/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Decoupled DMD for Diffusion Language Models","name":"Decoupled DMD for Diffusion Language Models","description":"Decoupled DMD for Diffusion Language Models: The Spear \u0026 The Shield","keywords":[],"articleBody":"Decoupled DMD for Diffusion Language Models: The Spear \u0026 The Shield Recent research into Decoupled DMD (Distribution Matching Distillation) fundamentally changes how we understand diffusion distillation. It argues that the “magic” of shrinking a 50-step diffusion model into a 1-step generator isn’t just about matching distributions—it’s about a specific division of labor.\nThe Spear (CFG Augmentation): The driving force that pushes the model toward high-quality concepts.\nThe Shield (Distribution Matching): The regularizer that prevents the model from collapsing into artifacts or oversaturated “garbage.”\nYes, you can implement this for a Diffusion Language Model (DLM), but it requires translating the mechanics from continuous (pixels/Gaussian noise) to discrete (tokens/Categorical noise).\n1. The Concept: Why Decoupling Matters for Language In standard DLMs (like MDLM, SSD-LM, or Discrete Flow Matching), you typically distill by forcing the student to match the teacher’s probability distribution.\nThe Decoupled DMD insight suggests that if you just try to “match the distribution,” the student struggles to learn high-quality, prompt-aligned text quickly. You need to explicitly inject the teacher’s “guidance” signal (the Spear) to force alignment, while using the distribution loss (the Shield) to keep the grammar and syntax valid.\n2. The Implementation Blueprint A. The Spear: CFG Augmentation (CA) for Tokens In image diffusion, the “Spear” is a gradient update derived from the teacher’s CFG output. In discrete language modeling, this becomes a logit-space target.\nContinuous (Image): The student pushes its pixels in the direction of $(\\text{Cond\\_Noise} - \\text{Uncond\\_Noise})$.\nDiscrete (Language): The student learns to predict Sharpened Logits.\nHow to Implement:\nInstead of training the student on the teacher’s raw logits $L_{teacher}$, you construct a “Guidance Target” ($L_{spear}$):\n$$L_{spear} = L_{cond} + w \\cdot (L_{cond} - L_{uncond})$$ $L_{cond}$: The teacher’s logits given the text prompt.\n$L_{uncond}$: The teacher’s logits given an empty/null prompt.\n$w$: The guidance scale (e.g., 2.0 - 5.0).\nThe Mechanism:\nYour student model attempts to minimize the Cross-Entropy (or KL Divergence) between its predicted logits and this new “Spear” target $L_{spear}$. This forces the student to “over-attend” to the prompt keywords, which is critical for few-step generation.\nB. The Shield: Distribution Matching (DM) If you only use the Spear, your language model will likely generate “keyword soup”—repetitive, grammatically broken text that is semantically intense but syntactically garbage (oversaturation). You need the Shield to force the output to remain “real language.”\nContinuous (Image): Uses a “Fake Score” discriminator to measure the distance between student images and real image distribution.\nDiscrete (Language): Use a Language Discriminator or Ratio Estimator.\nHow to Implement:\nGenerate Samples: Run your student DLM for 1-4 steps to produce a sequence $x_{student}$.\nTeacher Scoring: Pass $x_{student}$ through the frozen Teacher model to get its likelihood (or score).\nThe Loss: Minimize a divergence (like Reverse KL) that penalizes the student if $x_{student}$ has low probability under the Teacher’s “standard” (un-guided) distribution.\nSimplified Shield Objective:\n$$\\mathcal{L}_{shield} = \\mathbb{E}_{x \\sim Student} \\left[ \\log \\frac{p_{student}(x)}{p_{teacher}(x)} \\right]$$ Note: Since differentiating through discrete samples is hard, you will likely need to use REINFORCE (policy gradient) or a Gumbel-Softmax relaxation to backpropagate this loss to the student.\n3. Structural Comparison: Image vs. Language Component Image Diffusion (Original DMD) Diffusion Language Model (Proposed) Data Type Continuous (Pixels) Discrete (Tokens / One-Hot) The Spear (Engine) Gradient update: $\\nabla ( \\epsilon_c - \\epsilon_u )$ Target Logits: $L_c + w(L_c - L_u)$ The Shield (Regularizer) Score Difference (Real vs. Fake Score) Ratio Estimation / Discriminator Loss Backprop Method Direct Chain Rule Gumbel-Softmax or Policy Gradient Failure Mode w/o Shield Oversaturated, fried images Repetitive words, broken grammar 4. Technical Challenges \u0026 Solutions The “Discrete Gradient” Problem Decoupled DMD relies heavily on precise gradient updates. In language, you cannot slightly adjust a token “index.”\nSolution: Perform the distillation in the continuous embedding space (before the final discrete projection) or use Simplex Diffusion where the diffusion happens on the probability simplex rather than hard tokens. Guidance Scale Sensitivity Language models are notoriously sensitive to CFG scales (the “Spear” weight). Too high, and they speak nonsense.\nSolution: Use a much lower guidance scale ($w \\approx 1.5 - 2.0$) than images use. You might also need dynamic guidance, where the Spear is sharp at early diffusion steps (determining topic) and weak at later steps (determining grammar). 5. Why this is promising for DLMs Current Diffusion Language Models lag behind Autoregressive models (like Llama/GPT) because they lack “precision” in few-step sampling. They often drift off-topic.\nBy applying Decoupled DMD, you effectively force the student to “hallucinate” the topic strongly (via the Spear) while constraining it to speak English (via the Shield). This could be the key to making non-autoregressive text generation competitive.\n","wordCount":"761","inLanguage":"en","datePublished":"2026-01-20T10:50:21+05:30","dateModified":"2026-01-20T10:50:21+05:30","author":{"@type":"Person","name":"Nikhil Satani"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://satani99.github.io/posts/decoupled-dmd-for-diffusion-language-models/"},"publisher":{"@type":"Organization","name":"Nikhil's blog","logo":{"@type":"ImageObject","url":"https://satani99.github.io/favicon.ico"}}}</script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.25/dist/katex.min.css integrity=sha384-WcoG4HRXMzYzfCgiyfrySxx90XSl2rxY5mnVY5TwtWE6KLrArNKn0T/mOgNL0Mmi crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.25/dist/katex.min.js integrity=sha384-J+9dG2KMoiR9hqcFao0IBLwxt6zpcyN68IgwzsCSkbreXUjmNVRhPFTssqdSGjwQ crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.25/dist/contrib/auto-render.min.js integrity=sha384-hCXGrW6PitJEwbkoStFjeJxv+fSOOQKOPbJxSfM6G5sWZjAyWhXiTIIAmQqnlLlh crossorigin=anonymous onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"\\[",right:"\\]",display:!0},{left:"$$",right:"$$",display:!0},{left:"\\(",right:"\\)",display:!1}],throwOnError:!1})})</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://satani99.github.io/ accesskey=h title="Nikhil's blog (Alt + H)">Nikhil's blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Decoupled DMD for Diffusion Language Models</h1><div class=post-description>Decoupled DMD for Diffusion Language Models: The Spear & The Shield</div><div class=post-meta><span title='2026-01-20 10:50:21 +0530 IST'>January 20, 2026</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;Nikhil Satani</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#decoupled-dmd-for-diffusion-language-models-the-spear--the-shield aria-label="Decoupled DMD for Diffusion Language Models: The Spear & The Shield">Decoupled DMD for Diffusion Language Models: The Spear & The Shield</a><ul><li><a href=#1-the-concept-why-decoupling-matters-for-language aria-label="1. The Concept: Why Decoupling Matters for Language">1. The Concept: Why Decoupling Matters for Language</a></li><li><a href=#2-the-implementation-blueprint aria-label="2. The Implementation Blueprint">2. The Implementation Blueprint</a><ul><li><a href=#a-the-spear-cfg-augmentation-ca-for-tokens aria-label="A. The Spear: CFG Augmentation (CA) for Tokens">A. The Spear: CFG Augmentation (CA) for Tokens</a></li><li><a href=#b-the-shield-distribution-matching-dm aria-label="B. The Shield: Distribution Matching (DM)">B. The Shield: Distribution Matching (DM)</a></li></ul></li><li><a href=#3-structural-comparison-image-vs-language aria-label="3. Structural Comparison: Image vs. Language">3. Structural Comparison: Image vs. Language</a></li><li><a href=#4-technical-challenges--solutions aria-label="4. Technical Challenges & Solutions">4. Technical Challenges & Solutions</a><ul><li><a href=#the-discrete-gradient-problem aria-label="The &ldquo;Discrete Gradient&rdquo; Problem">The &ldquo;Discrete Gradient&rdquo; Problem</a></li><li><a href=#guidance-scale-sensitivity aria-label="Guidance Scale Sensitivity">Guidance Scale Sensitivity</a></li></ul></li><li><a href=#5-why-this-is-promising-for-dlms aria-label="5. Why this is promising for DLMs">5. Why this is promising for DLMs</a></li></ul></li></ul></div></details></div><div class=post-content><h1 id=decoupled-dmd-for-diffusion-language-models-the-spear--the-shield>Decoupled DMD for Diffusion Language Models: The Spear & The Shield<a hidden class=anchor aria-hidden=true href=#decoupled-dmd-for-diffusion-language-models-the-spear--the-shield>#</a></h1><p>Recent research into <strong>Decoupled DMD</strong> (Distribution Matching Distillation) fundamentally changes how we understand diffusion distillation. It argues that the &ldquo;magic&rdquo; of shrinking a 50-step diffusion model into a 1-step generator isn&rsquo;t just about matching distributions—it&rsquo;s about a specific <strong>division of labor</strong>.</p><ul><li><p><strong>The Spear (CFG Augmentation):</strong> The driving force that pushes the model toward high-quality concepts.</p></li><li><p><strong>The Shield (Distribution Matching):</strong> The regularizer that prevents the model from collapsing into artifacts or oversaturated &ldquo;garbage.&rdquo;</p></li></ul><p><strong>Yes, you can implement this for a Diffusion Language Model (DLM),</strong> but it requires translating the mechanics from continuous (pixels/Gaussian noise) to discrete (tokens/Categorical noise).</p><hr><h2 id=1-the-concept-why-decoupling-matters-for-language>1. The Concept: Why Decoupling Matters for Language<a hidden class=anchor aria-hidden=true href=#1-the-concept-why-decoupling-matters-for-language>#</a></h2><p>In standard DLMs (like MDLM, SSD-LM, or Discrete Flow Matching), you typically distill by forcing the student to match the teacher&rsquo;s probability distribution.</p><p>The <strong>Decoupled DMD</strong> insight suggests that if you just try to &ldquo;match the distribution,&rdquo; the student struggles to learn high-quality, prompt-aligned text quickly. You need to explicitly inject the teacher&rsquo;s &ldquo;guidance&rdquo; signal (the Spear) to force alignment, while using the distribution loss (the Shield) to keep the grammar and syntax valid.</p><hr><h2 id=2-the-implementation-blueprint>2. The Implementation Blueprint<a hidden class=anchor aria-hidden=true href=#2-the-implementation-blueprint>#</a></h2><h3 id=a-the-spear-cfg-augmentation-ca-for-tokens>A. The Spear: CFG Augmentation (CA) for Tokens<a hidden class=anchor aria-hidden=true href=#a-the-spear-cfg-augmentation-ca-for-tokens>#</a></h3><p>In image diffusion, the &ldquo;Spear&rdquo; is a gradient update derived from the teacher&rsquo;s CFG output. In discrete language modeling, this becomes a <strong>logit-space target</strong>.</p><ul><li><p><strong>Continuous (Image):</strong> The student pushes its pixels in the direction of $(\text{Cond\_Noise} - \text{Uncond\_Noise})$.</p></li><li><p><strong>Discrete (Language):</strong> The student learns to predict <strong>Sharpened Logits</strong>.</p></li></ul><p>How to Implement:</p><p>Instead of training the student on the teacher&rsquo;s raw logits $L_{teacher}$, you construct a &ldquo;Guidance Target&rdquo; ($L_{spear}$):</p>$$L_{spear} = L_{cond} + w \cdot (L_{cond} - L_{uncond})$$<ul><li><p>$L_{cond}$: The teacher&rsquo;s logits given the text prompt.</p></li><li><p>$L_{uncond}$: The teacher&rsquo;s logits given an empty/null prompt.</p></li><li><p>$w$: The guidance scale (e.g., 2.0 - 5.0).</p></li></ul><p>The Mechanism:</p><p>Your student model attempts to minimize the Cross-Entropy (or KL Divergence) between its predicted logits and this new &ldquo;Spear&rdquo; target $L_{spear}$. This forces the student to &ldquo;over-attend&rdquo; to the prompt keywords, which is critical for few-step generation.</p><h3 id=b-the-shield-distribution-matching-dm>B. The Shield: Distribution Matching (DM)<a hidden class=anchor aria-hidden=true href=#b-the-shield-distribution-matching-dm>#</a></h3><p>If you <em>only</em> use the Spear, your language model will likely generate &ldquo;keyword soup&rdquo;—repetitive, grammatically broken text that is semantically intense but syntactically garbage (oversaturation). You need the Shield to force the output to remain &ldquo;real language.&rdquo;</p><ul><li><p><strong>Continuous (Image):</strong> Uses a &ldquo;Fake Score&rdquo; discriminator to measure the distance between student images and real image distribution.</p></li><li><p><strong>Discrete (Language):</strong> Use a <strong>Language Discriminator</strong> or <strong>Ratio Estimator</strong>.</p></li></ul><p><strong>How to Implement:</strong></p><ol><li><p><strong>Generate Samples:</strong> Run your student DLM for 1-4 steps to produce a sequence $x_{student}$.</p></li><li><p><strong>Teacher Scoring:</strong> Pass $x_{student}$ through the frozen Teacher model to get its likelihood (or score).</p></li><li><p><strong>The Loss:</strong> Minimize a divergence (like Reverse KL) that penalizes the student if $x_{student}$ has low probability under the Teacher&rsquo;s &ldquo;standard&rdquo; (un-guided) distribution.</p></li></ol><p>Simplified Shield Objective:</p>$$\mathcal{L}_{shield} = \mathbb{E}_{x \sim Student} \left[ \log \frac{p_{student}(x)}{p_{teacher}(x)} \right]$$<p><em>Note:</em> Since differentiating through discrete samples is hard, you will likely need to use <strong>REINFORCE</strong> (policy gradient) or a <strong>Gumbel-Softmax</strong> relaxation to backpropagate this loss to the student.</p><hr><h2 id=3-structural-comparison-image-vs-language>3. Structural Comparison: Image vs. Language<a hidden class=anchor aria-hidden=true href=#3-structural-comparison-image-vs-language>#</a></h2><table><thead><tr><th><strong>Component</strong></th><th><strong>Image Diffusion (Original DMD)</strong></th><th><strong>Diffusion Language Model (Proposed)</strong></th></tr></thead><tbody><tr><td><strong>Data Type</strong></td><td>Continuous (Pixels)</td><td>Discrete (Tokens / One-Hot)</td></tr><tr><td><strong>The Spear (Engine)</strong></td><td>Gradient update: $\nabla ( \epsilon_c - \epsilon_u )$</td><td>Target Logits: $L_c + w(L_c - L_u)$</td></tr><tr><td><strong>The Shield (Regularizer)</strong></td><td>Score Difference (Real vs. Fake Score)</td><td>Ratio Estimation / Discriminator Loss</td></tr><tr><td><strong>Backprop Method</strong></td><td>Direct Chain Rule</td><td>Gumbel-Softmax or Policy Gradient</td></tr><tr><td><strong>Failure Mode w/o Shield</strong></td><td>Oversaturated, fried images</td><td>Repetitive words, broken grammar</td></tr></tbody></table><hr><h2 id=4-technical-challenges--solutions>4. Technical Challenges & Solutions<a hidden class=anchor aria-hidden=true href=#4-technical-challenges--solutions>#</a></h2><h3 id=the-discrete-gradient-problem>The &ldquo;Discrete Gradient&rdquo; Problem<a hidden class=anchor aria-hidden=true href=#the-discrete-gradient-problem>#</a></h3><p>Decoupled DMD relies heavily on precise gradient updates. In language, you cannot slightly adjust a token &ldquo;index.&rdquo;</p><ul><li><strong>Solution:</strong> Perform the distillation in the <strong>continuous embedding space</strong> (before the final discrete projection) or use <strong>Simplex Diffusion</strong> where the diffusion happens on the probability simplex rather than hard tokens.</li></ul><h3 id=guidance-scale-sensitivity>Guidance Scale Sensitivity<a hidden class=anchor aria-hidden=true href=#guidance-scale-sensitivity>#</a></h3><p>Language models are notoriously sensitive to CFG scales (the &ldquo;Spear&rdquo; weight). Too high, and they speak nonsense.</p><ul><li><strong>Solution:</strong> Use a much lower guidance scale ($w \approx 1.5 - 2.0$) than images use. You might also need <strong>dynamic guidance</strong>, where the Spear is sharp at early diffusion steps (determining topic) and weak at later steps (determining grammar).</li></ul><hr><h2 id=5-why-this-is-promising-for-dlms>5. Why this is promising for DLMs<a hidden class=anchor aria-hidden=true href=#5-why-this-is-promising-for-dlms>#</a></h2><p>Current Diffusion Language Models lag behind Autoregressive models (like Llama/GPT) because they lack &ldquo;precision&rdquo; in few-step sampling. They often drift off-topic.</p><p>By applying <strong>Decoupled DMD</strong>, you effectively force the student to &ldquo;hallucinate&rdquo; the topic strongly (via the Spear) while constraining it to speak English (via the Shield). This could be the key to making non-autoregressive text generation competitive.</p></div><footer class=post-footer><ul class=post-tags></ul><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Decoupled DMD for Diffusion Language Models on x" href="https://x.com/intent/tweet/?text=Decoupled%20DMD%20for%20Diffusion%20Language%20Models&amp;url=https%3a%2f%2fsatani99.github.io%2fposts%2fdecoupled-dmd-for-diffusion-language-models%2f&amp;hashtags="><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Decoupled DMD for Diffusion Language Models on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fsatani99.github.io%2fposts%2fdecoupled-dmd-for-diffusion-language-models%2f&amp;title=Decoupled%20DMD%20for%20Diffusion%20Language%20Models&amp;summary=Decoupled%20DMD%20for%20Diffusion%20Language%20Models&amp;source=https%3a%2f%2fsatani99.github.io%2fposts%2fdecoupled-dmd-for-diffusion-language-models%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Decoupled DMD for Diffusion Language Models on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fsatani99.github.io%2fposts%2fdecoupled-dmd-for-diffusion-language-models%2f&title=Decoupled%20DMD%20for%20Diffusion%20Language%20Models"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Decoupled DMD for Diffusion Language Models on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fsatani99.github.io%2fposts%2fdecoupled-dmd-for-diffusion-language-models%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Decoupled DMD for Diffusion Language Models on whatsapp" href="https://api.whatsapp.com/send?text=Decoupled%20DMD%20for%20Diffusion%20Language%20Models%20-%20https%3a%2f%2fsatani99.github.io%2fposts%2fdecoupled-dmd-for-diffusion-language-models%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Decoupled DMD for Diffusion Language Models on telegram" href="https://telegram.me/share/url?text=Decoupled%20DMD%20for%20Diffusion%20Language%20Models&amp;url=https%3a%2f%2fsatani99.github.io%2fposts%2fdecoupled-dmd-for-diffusion-language-models%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Decoupled DMD for Diffusion Language Models on ycombinator" href="https://news.ycombinator.com/submitlink?t=Decoupled%20DMD%20for%20Diffusion%20Language%20Models&u=https%3a%2f%2fsatani99.github.io%2fposts%2fdecoupled-dmd-for-diffusion-language-models%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2026 <a href=https://satani99.github.io/>Nikhil's blog</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>