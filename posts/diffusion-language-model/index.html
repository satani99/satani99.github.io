<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Diffusion Language Model | Nikhil&#39;s blog</title>
<meta name="keywords" content="">
<meta name="description" content="How Diffusion Language Models Work: Theory, Implementation, and Code">
<meta name="author" content="Nikhil Satani">
<link rel="canonical" href="https://satani99.github.io/posts/diffusion-language-model/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.fc220c15db4aef0318bbf30adc45d33d4d7c88deff3238b23eb255afdc472ca6.css" integrity="sha256-/CIMFdtK7wMYu/MK3EXTPU18iN7/MjiyPrJVr9xHLKY=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://satani99.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://satani99.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://satani99.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://satani99.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://satani99.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://satani99.github.io/posts/diffusion-language-model/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:title" content="Diffusion Language Model" />
<meta property="og:description" content="How Diffusion Language Models Work: Theory, Implementation, and Code" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://satani99.github.io/posts/diffusion-language-model/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2025-01-20T18:59:37+05:30" />
<meta property="article:modified_time" content="2025-01-20T18:59:37+05:30" /><meta property="og:site_name" content="Nikhil&#39;s blog" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Diffusion Language Model"/>
<meta name="twitter:description" content="How Diffusion Language Models Work: Theory, Implementation, and Code"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://satani99.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Diffusion Language Model",
      "item": "https://satani99.github.io/posts/diffusion-language-model/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Diffusion Language Model",
  "name": "Diffusion Language Model",
  "description": "How Diffusion Language Models Work: Theory, Implementation, and Code",
  "keywords": [
    
  ],
  "articleBody": "How Diffusion Language Models Work: Theory, Implementation, and Code Diffusion language models (DLMs) represent a revolutionary paradigm shift in text generation, offering compelling alternatives to the autoregressive models that currently dominate natural language processing. Unlike traditional language models that generate text sequentially from left to right, diffusion models employ an iterative denoising process that enables parallel generation, enhanced controllability, and novel capabilities like bidirectional reasoning1 2.\nThe Core Principle: From Noise to Text At their fundamental level, diffusion language models operate through two complementary processes that mirror the proven success of image generation models. The forward diffusion process systematically destroys text structure by gradually corrupting clean text over multiple timesteps, while the reverse diffusion process learns to progressively denoise corrupted text back to its original form3 4.\nForward Diffusion Process The forward process transforms structured text into noise through a predetermined Markov chain. For discrete text tokens, this involves using transition matrices that probabilistically replace original tokens with noise or mask tokens. The most sophisticated approaches employ Discrete Denoising Diffusion Probabilistic Models (D3PM) with transition matrices $Q_t$ where each token can change to other vocabulary items with carefully designed probabilities5 6.\nIn the absorbing state diffusion used by many language models, the forward process gradually masks tokens according to:\n$q(\\mathbf{z}_t|\\mathbf{x}) = \\mathrm{Cat}(\\mathbf{z}_t; \\alpha_t \\mathbf{x} + (1-\\alpha_t) \\boldsymbol{\\pi})$\nwhere $\\alpha_t$ is a decreasing function controlling the noise level, and $\\boldsymbol{\\pi}$ represents the mask token distribution7 8.\nReverse Diffusion Process The reverse process represents the core innovation, where neural networks learn to predict what the original clean text should be at each denoising step. This is mathematically formulated as learning $p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_t)$, reversing the corruption process step by step9 3.\nKey Architectural Innovations Modern DLMs leverage transformer architectures with critical modifications for handling the diffusion process. The Diffusion Transformer (DiT) incorporates timestep conditioning through sinusoidal time embeddings and adaptive layer normalization, allowing the model to adjust its denoising strategy based on the current noise level10 11.\nRecent breakthroughs like LLaDA (Large Language Diffusion with mAsking) demonstrate the scalability of diffusion architectures. LLaDA employs a masked diffusion process where tokens are randomly masked during pretraining, while the reverse process uses a transformer to predict all masked tokens simultaneously11 12.\nScore Entropy Discrete Diffusion (SEDD) A major breakthrough came with Score Entropy Discrete Diffusion (SEDD), which revolutionized the training process by modeling ratios between data distributions rather than absolute probabilities. Instead of directly modeling $p_\\theta(\\mathbf{x})$, SEDD learns concrete scores $s_\\theta(\\mathbf{x})y \\approx p{\\text{data}}(y)/p_{\\text{data}}(\\mathbf{x})$, eliminating intractable normalization constants and achieving 25-75% improvements in perplexity over previous diffusion approaches13 14 15.\nMasked Diffusion Language Models (MDLM) The Masked Diffusion Language Model (MDLM) framework introduces a novel substitution-based parameterization that simplifies the absorbing state diffusion loss to a mixture of classical masked language modeling losses. This approach achieves state-of-the-art performance among diffusion models while approaching autoregressive model perplexity1 7 8.\nAdvantages and Applications Diffusion language models offer several unique advantages over autoregressive approaches:\nParallel Generation: Unlike autoregressive models that generate tokens sequentially, diffusion models can generate multiple tokens simultaneously, potentially offering significant speedup advantages16 17.\nBidirectional Context: DLMs can condition on both past and future context, enabling capabilities like infilling and solving the “reversal curse” that plagues autoregressive models2 11 12.\nEnhanced Controllability: The iterative refinement process allows for fine-grained control over generation through classifier guidance and other steering mechanisms18 10.\nFlexible Length Generation: Recent developments enable generation of arbitrary-length sequences through semi-autoregressive approaches19 17.\nSimple PyTorch Implementation Here’s a basic implementation of a masked diffusion language model in PyTorch:\nimport torch import torch.nn as nn import torch.nn.functional as F import math class MaskedDiffusionLM(nn.Module): \"\"\" A simple masked diffusion language model implementation. Based on the MDLM framework with absorbing state diffusion. \"\"\" def __init__(self, vocab_size, d_model=512, n_heads=8, n_layers=6, max_len=1024): super().__init__() self.vocab_size = vocab_size self.d_model = d_model self.max_len = max_len self.mask_token_id = vocab_size - 1 # Reserve last token as mask # Token and position embeddings self.token_embedding = nn.Embedding(vocab_size, d_model) self.pos_embedding = nn.Embedding(max_len, d_model) # Time embedding for diffusion timestep self.time_embedding = TimeEmbedding(d_model) # Transformer layers self.transformer_layers = nn.ModuleList([ TransformerBlock(d_model, n_heads) for _ in range(n_layers) ]) # Output projection self.output_proj = nn.Linear(d_model, vocab_size) self.layer_norm = nn.LayerNorm(d_model) def forward(self, x, t): \"\"\" Forward pass for training. Args: x: Token sequences [batch_size, seq_len] t: Diffusion timesteps [batch_size] \"\"\" batch_size, seq_len = x.shape # Token embeddings token_emb = self.token_embedding(x) # Position embeddings positions = torch.arange(seq_len, device=x.device).unsqueeze(0).expand(batch_size, -1) pos_emb = self.pos_embedding(positions) # Time embeddings time_emb = self.time_embedding(t) # [batch_size, d_model] time_emb = time_emb.unsqueeze(1).expand(-1, seq_len, -1) # Combine embeddings x = token_emb + pos_emb + time_emb # Apply transformer layers for layer in self.transformer_layers: x = layer(x) x = self.layer_norm(x) # Output logits logits = self.output_proj(x) return logits class TimeEmbedding(nn.Module): \"\"\"Sinusoidal time embedding for diffusion timesteps.\"\"\" def __init__(self, d_model): super().__init__() self.d_model = d_model def forward(self, t): \"\"\" Args: t: Timesteps [batch_size] Returns: Time embeddings [batch_size, d_model] \"\"\" half_dim = self.d_model // 2 emb = math.log(10000) / (half_dim - 1) emb = torch.exp(torch.arange(half_dim, device=t.device) * -emb) emb = t[:, None] * emb[None, :] emb = torch.cat([emb.sin(), emb.cos()], dim=1) return emb class TransformerBlock(nn.Module): \"\"\"Standard transformer block with self-attention and feed-forward.\"\"\" def __init__(self, d_model, n_heads): super().__init__() self.attention = nn.MultiheadAttention(d_model, n_heads, batch_first=True) self.norm1 = nn.LayerNorm(d_model) self.norm2 = nn.LayerNorm(d_model) self.feed_forward = nn.Sequential( nn.Linear(d_model, 4 * d_model), nn.GELU(), nn.Linear(4 * d_model, d_model) ) def forward(self, x): # Self-attention with residual connection attn_out, _ = self.attention(x, x, x) x = self.norm1(x + attn_out) # Feed-forward with residual connection ff_out = self.feed_forward(x) x = self.norm2(x + ff_out) return x class DiffusionTrainer: \"\"\"Training utilities for masked diffusion language model.\"\"\" def __init__(self, model, vocab_size): self.model = model self.vocab_size = vocab_size self.mask_token_id = vocab_size - 1 def q_sample(self, x_0, t): \"\"\" Sample from q(x_t | x_0) - the forward diffusion process. Implements absorbing state diffusion with masking. \"\"\" batch_size, seq_len = x_0.shape # Compute noise schedule (linear for simplicity) alpha_t = 1.0 - t.float() / 1000.0 # Assume 1000 timesteps alpha_t = alpha_t.clamp(0.01, 0.99) # Avoid complete masking # Create mask probabilities mask_prob = (1 - alpha_t).unsqueeze(1).expand(-1, seq_len) # Sample which tokens to mask should_mask = torch.rand_like(mask_prob) \u003c mask_prob # Apply masking x_t = x_0.clone() x_t[should_mask] = self.mask_token_id return x_t, should_mask def compute_loss(self, x_0, model_output, mask): \"\"\" Compute the simplified MDLM loss. This is a mixture of masked language modeling losses. \"\"\" # Only compute loss on masked positions masked_positions = mask if masked_positions.sum() == 0: return torch.tensor(0.0, device=x_0.device) # Extract predictions and targets for masked positions predictions = model_output[masked_positions] targets = x_0[masked_positions] # Compute cross-entropy loss loss = F.cross_entropy(predictions, targets) return loss def training_step(self, batch, optimizer): \"\"\"Single training step.\"\"\" x_0 = batch # Clean text tokens batch_size = x_0.shape[^0] # Sample random timesteps t = torch.randint(0, 1000, (batch_size,), device=x_0.device) # Forward diffusion: add noise x_t, mask = self.q_sample(x_0, t) # Model prediction logits = self.model(x_t, t) # Compute loss loss = self.compute_loss(x_0, logits, mask) # Backward pass optimizer.zero_grad() loss.backward() optimizer.step() return loss.item() class DiffusionSampler: \"\"\"Sampling utilities for generating text.\"\"\" def __init__(self, model, vocab_size, num_timesteps=1000): self.model = model self.vocab_size = vocab_size self.mask_token_id = vocab_size - 1 self.num_timesteps = num_timesteps @torch.no_grad() def sample(self, batch_size, seq_len, device='cuda'): \"\"\" Generate samples using the reverse diffusion process. \"\"\" # Start with all masked tokens x = torch.full((batch_size, seq_len), self.mask_token_id, dtype=torch.long, device=device) # Reverse diffusion process for t in reversed(range(self.num_timesteps)): t_batch = torch.full((batch_size,), t, device=device) # Model prediction logits = self.model(x, t_batch) # Sample from the predicted distribution for masked positions mask_positions = (x == self.mask_token_id) if mask_positions.sum() \u003e 0: # Sample new tokens for masked positions probs = F.softmax(logits[mask_positions], dim=-1) # Avoid sampling the mask token probs[:, self.mask_token_id] = 0 probs = probs / probs.sum(dim=-1, keepdim=True) new_tokens = torch.multinomial(probs, 1).squeeze(-1) x[mask_positions] = new_tokens return x # Usage example def train_diffusion_model(): \"\"\"Example training script.\"\"\" # Model hyperparameters vocab_size = 10000 # Including mask token d_model = 512 n_heads = 8 n_layers = 6 max_len = 256 # Initialize model and trainer model = MaskedDiffusionLM(vocab_size, d_model, n_heads, n_layers, max_len) trainer = DiffusionTrainer(model, vocab_size) # Optimizer optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4) # Training loop (simplified) model.train() for epoch in range(10): for batch_idx, batch in enumerate(dataloader): # Your data loader here loss = trainer.training_step(batch, optimizer) if batch_idx % 100 == 0: print(f\"Epoch {epoch}, Batch {batch_idx}, Loss: {loss:.4f}\") return model # Generation example def generate_text(model, vocab_size): \"\"\"Example text generation.\"\"\" sampler = DiffusionSampler(model, vocab_size) model.eval() samples = sampler.sample(batch_size=4, seq_len=128, device='cuda') return samples if __name__ == \"__main__\": # Train the model trained_model = train_diffusion_model() # Generate samples generated_samples = generate_text(trained_model, vocab_size=10000) print(\"Generated samples shape:\", generated_samples.shape) Advanced Implementation Features For production-ready implementations, several advanced features should be considered:\nNoise Scheduling: More sophisticated noise schedules like cosine or learned schedules can significantly improve performance20 8.\nEfficient Sampling: Techniques like cached sampling can provide 3-4x speedup over naive ancestral sampling21 22.\nSemi-Autoregressive Generation: Extending generation to arbitrary lengths through stride-based approaches19 21.\nClassifier-Free Guidance: Enabling controllable generation without explicit classifiers10 23.\nCurrent Limitations and Future Directions While diffusion language models show tremendous promise, they face several challenges. They typically exhibit slower inference than autoregressive models for short sequences, though this gap narrows for longer generations16 24. Training complexity remains higher than autoregressive approaches, and performance on complex reasoning tasks still lags behind state-of-the-art autoregressive models24 25.\nHowever, recent developments suggest these limitations are surmountable engineering challenges rather than fundamental barriers. The emergence of hybrid architectures, scaling successes like LLaDA, and theoretical advances like SEDD position DLMs as a complementary and potentially superior approach for specific applications requiring sophisticated control, creativity, and bidirectional reasoning2 10 11.\nThe field stands at a critical juncture where continued investment could establish diffusion as the preferred paradigm for controllable, high-quality text generation, while hybrid approaches may ultimately combine the best aspects of both autoregressive and diffusion methods10 26. For practitioners and researchers, DLMs represent not just an alternative to current approaches, but a fundamentally different way of thinking about language generation that opens new possibilities for AI applications.\nhttps://arxiv.org/abs/2406.07524 ↩︎ ↩︎\nhttps://arxiv.org/abs/2410.17891 ↩︎ ↩︎ ↩︎\nhttps://assemblyai.com/blog/diffusion-models-for-machine-learning-introduction ↩︎ ↩︎\nhttps://lilianweng.github.io/posts/2021-07-11-diffusion-models/ ↩︎\nhttps://papers.neurips.cc/paper/2021/file/958c530554f78bcd8e97125b70e6973d-Paper.pdf ↩︎\nhttps://openreview.net/forum?id=h7-XixPCAL ↩︎\nhttps://s-sahoo.com/mdlm/ ↩︎ ↩︎\nhttps://openreview.net/pdf?id=L4uaAR4ArM ↩︎ ↩︎ ↩︎\nhttps://theaisummer.com/diffusion-models/ ↩︎\nhttps://huggingface.co/blog/ProCreations/diffusion-language-model ↩︎ ↩︎ ↩︎ ↩︎ ↩︎\nhttps://ml-gsai.github.io/LLaDA-demo/ ↩︎ ↩︎ ↩︎ ↩︎\nhttps://arxiv.org/abs/2502.09992 ↩︎ ↩︎\nhttps://www.semanticscholar.org/paper/ce806f8d32f6fb1eaa821248a1bc4fa2cd949fbb ↩︎\nhttps://arxiv.org/pdf/2310.16834.pdf ↩︎\nhttps://arxiv.org/abs/2310.16834 ↩︎\nhttps://www.seangoedecke.com/limitations-of-text-diffusion-models/ ↩︎ ↩︎\nhttps://arxiv.org/abs/2506.19037 ↩︎ ↩︎\nhttps://arxiv.org/abs/2402.07754 ↩︎\nhttps://arxiv.org/abs/2503.09573 ↩︎ ↩︎\nhttps://arxiv.org/abs/2406.04329 ↩︎\nhttps://github.com/kuleshov-group/mdlm ↩︎ ↩︎\nhttps://openreview.net/forum?id=L4uaAR4ArM ↩︎\nhttps://arxiv.org/html/2408.04220v1 ↩︎\nhttps://arxiv.org/abs/2406.11473 ↩︎ ↩︎\nhttps://arxiv.org/abs/2409.02908 ↩︎\nhttps://openreview.net/forum?id=j1tSLYKwg8 ↩︎\n",
  "wordCount" : "1660",
  "inLanguage": "en",
  "datePublished": "2025-01-20T18:59:37+05:30",
  "dateModified": "2025-01-20T18:59:37+05:30",
  "author":{
    "@type": "Person",
    "name": "Nikhil Satani"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://satani99.github.io/posts/diffusion-language-model/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Nikhil's blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://satani99.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://satani99.github.io/" accesskey="h" title="Nikhil&#39;s blog (Alt + H)">Nikhil&#39;s blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Diffusion Language Model
    </h1>
    <div class="post-description">
      How Diffusion Language Models Work: Theory, Implementation, and Code
    </div>
    <div class="post-meta"><span title='2025-01-20 18:59:37 +0530 IST'>January 20, 2025</span>&nbsp;·&nbsp;8 min&nbsp;·&nbsp;Nikhil Satani

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#how-diffusion-language-models-work-theory-implementation-and-code" aria-label="How Diffusion Language Models Work: Theory, Implementation, and Code">How Diffusion Language Models Work: Theory, Implementation, and Code</a><ul>
                        
                <li>
                    <a href="#the-core-principle-from-noise-to-text" aria-label="The Core Principle: From Noise to Text">The Core Principle: From Noise to Text</a><ul>
                        
                <li>
                    <a href="#forward-diffusion-process" aria-label="Forward Diffusion Process">Forward Diffusion Process</a></li>
                <li>
                    <a href="#reverse-diffusion-process" aria-label="Reverse Diffusion Process">Reverse Diffusion Process</a></li></ul>
                </li>
                <li>
                    <a href="#key-architectural-innovations" aria-label="Key Architectural Innovations">Key Architectural Innovations</a><ul>
                        
                <li>
                    <a href="#score-entropy-discrete-diffusion-sedd" aria-label="Score Entropy Discrete Diffusion (SEDD)">Score Entropy Discrete Diffusion (SEDD)</a></li>
                <li>
                    <a href="#masked-diffusion-language-models-mdlm" aria-label="Masked Diffusion Language Models (MDLM)">Masked Diffusion Language Models (MDLM)</a></li></ul>
                </li>
                <li>
                    <a href="#advantages-and-applications" aria-label="Advantages and Applications">Advantages and Applications</a></li>
                <li>
                    <a href="#simple-pytorch-implementation" aria-label="Simple PyTorch Implementation">Simple PyTorch Implementation</a></li>
                <li>
                    <a href="#advanced-implementation-features" aria-label="Advanced Implementation Features">Advanced Implementation Features</a></li>
                <li>
                    <a href="#current-limitations-and-future-directions" aria-label="Current Limitations and Future Directions">Current Limitations and Future Directions</a>
                </li>
            </ul>
            </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h1 id="how-diffusion-language-models-work-theory-implementation-and-code">How Diffusion Language Models Work: Theory, Implementation, and Code<a hidden class="anchor" aria-hidden="true" href="#how-diffusion-language-models-work-theory-implementation-and-code">#</a></h1>
<p>Diffusion language models (DLMs) represent a revolutionary paradigm shift in text generation, offering compelling alternatives to the autoregressive models that currently dominate natural language processing. Unlike traditional language models that generate text sequentially from left to right, diffusion models employ an iterative denoising process that enables parallel generation, enhanced controllability, and novel capabilities like bidirectional reasoning<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> <sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>.</p>
<h2 id="the-core-principle-from-noise-to-text">The Core Principle: From Noise to Text<a hidden class="anchor" aria-hidden="true" href="#the-core-principle-from-noise-to-text">#</a></h2>
<p>At their fundamental level, diffusion language models operate through two complementary processes that mirror the proven success of image generation models. The <strong>forward diffusion process</strong> systematically destroys text structure by gradually corrupting clean text over multiple timesteps, while the <strong>reverse diffusion process</strong> learns to progressively denoise corrupted text back to its original form<sup id="fnref:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup> <sup id="fnref:4"><a href="#fn:4" class="footnote-ref" role="doc-noteref">4</a></sup>.</p>
<h3 id="forward-diffusion-process">Forward Diffusion Process<a hidden class="anchor" aria-hidden="true" href="#forward-diffusion-process">#</a></h3>
<p>The forward process transforms structured text into noise through a predetermined Markov chain. For discrete text tokens, this involves using transition matrices that probabilistically replace original tokens with noise or mask tokens. The most sophisticated approaches employ <strong>Discrete Denoising Diffusion Probabilistic Models (D3PM)</strong> with transition matrices $Q_t$ where each token can change to other vocabulary items with carefully designed probabilities<sup id="fnref:5"><a href="#fn:5" class="footnote-ref" role="doc-noteref">5</a></sup> <sup id="fnref:6"><a href="#fn:6" class="footnote-ref" role="doc-noteref">6</a></sup>.</p>
<p>In the absorbing state diffusion used by many language models, the forward process gradually masks tokens according to:</p>
<p>$q(\mathbf{z}_t|\mathbf{x}) = \mathrm{Cat}(\mathbf{z}_t; \alpha_t \mathbf{x} + (1-\alpha_t) \boldsymbol{\pi})$</p>
<p>where $\alpha_t$ is a decreasing function controlling the noise level, and $\boldsymbol{\pi}$ represents the mask token distribution<sup id="fnref:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup> <sup id="fnref:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>.</p>
<h3 id="reverse-diffusion-process">Reverse Diffusion Process<a hidden class="anchor" aria-hidden="true" href="#reverse-diffusion-process">#</a></h3>
<p>The reverse process represents the core innovation, where neural networks learn to predict what the original clean text should be at each denoising step. This is mathematically formulated as learning $p_\theta(\mathbf{x}_{t-1} | \mathbf{x}_t)$, reversing the corruption process step by step<sup id="fnref:9"><a href="#fn:9" class="footnote-ref" role="doc-noteref">9</a></sup> <sup id="fnref1:3"><a href="#fn:3" class="footnote-ref" role="doc-noteref">3</a></sup>.</p>
<h2 id="key-architectural-innovations">Key Architectural Innovations<a hidden class="anchor" aria-hidden="true" href="#key-architectural-innovations">#</a></h2>
<p>Modern DLMs leverage transformer architectures with critical modifications for handling the diffusion process. The <strong>Diffusion Transformer (DiT)</strong> incorporates timestep conditioning through sinusoidal time embeddings and adaptive layer normalization, allowing the model to adjust its denoising strategy based on the current noise level<sup id="fnref:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup> <sup id="fnref:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup>.</p>
<p>Recent breakthroughs like <strong>LLaDA (Large Language Diffusion with mAsking)</strong> demonstrate the scalability of diffusion architectures. LLaDA employs a masked diffusion process where tokens are randomly masked during pretraining, while the reverse process uses a transformer to predict all masked tokens simultaneously<sup id="fnref1:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup> <sup id="fnref:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup>.</p>
<h3 id="score-entropy-discrete-diffusion-sedd">Score Entropy Discrete Diffusion (SEDD)<a hidden class="anchor" aria-hidden="true" href="#score-entropy-discrete-diffusion-sedd">#</a></h3>
<p>A major breakthrough came with <strong>Score Entropy Discrete Diffusion (SEDD)</strong>, which revolutionized the training process by modeling ratios between data distributions rather than absolute probabilities. Instead of directly modeling $p_\theta(\mathbf{x})$, SEDD learns concrete scores $s_\theta(\mathbf{x})<em>y \approx p</em>{\text{data}}(y)/p_{\text{data}}(\mathbf{x})$, eliminating intractable normalization constants and achieving 25-75% improvements in perplexity over previous diffusion approaches<sup id="fnref:13"><a href="#fn:13" class="footnote-ref" role="doc-noteref">13</a></sup> <sup id="fnref:14"><a href="#fn:14" class="footnote-ref" role="doc-noteref">14</a></sup> <sup id="fnref:15"><a href="#fn:15" class="footnote-ref" role="doc-noteref">15</a></sup>.</p>
<h3 id="masked-diffusion-language-models-mdlm">Masked Diffusion Language Models (MDLM)<a hidden class="anchor" aria-hidden="true" href="#masked-diffusion-language-models-mdlm">#</a></h3>
<p>The <strong>Masked Diffusion Language Model (MDLM)</strong> framework introduces a novel substitution-based parameterization that simplifies the absorbing state diffusion loss to a mixture of classical masked language modeling losses. This approach achieves state-of-the-art performance among diffusion models while approaching autoregressive model perplexity<sup id="fnref1:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> <sup id="fnref1:7"><a href="#fn:7" class="footnote-ref" role="doc-noteref">7</a></sup> <sup id="fnref1:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>.</p>
<h2 id="advantages-and-applications">Advantages and Applications<a hidden class="anchor" aria-hidden="true" href="#advantages-and-applications">#</a></h2>
<p>Diffusion language models offer several unique advantages over autoregressive approaches:</p>
<p><strong>Parallel Generation</strong>: Unlike autoregressive models that generate tokens sequentially, diffusion models can generate multiple tokens simultaneously, potentially offering significant speedup advantages<sup id="fnref:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup> <sup id="fnref:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup>.</p>
<p><strong>Bidirectional Context</strong>: DLMs can condition on both past and future context, enabling capabilities like infilling and solving the &ldquo;reversal curse&rdquo; that plagues autoregressive models<sup id="fnref1:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> <sup id="fnref2:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup> <sup id="fnref1:12"><a href="#fn:12" class="footnote-ref" role="doc-noteref">12</a></sup>.</p>
<p><strong>Enhanced Controllability</strong>: The iterative refinement process allows for fine-grained control over generation through classifier guidance and other steering mechanisms<sup id="fnref:18"><a href="#fn:18" class="footnote-ref" role="doc-noteref">18</a></sup> <sup id="fnref1:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup>.</p>
<p><strong>Flexible Length Generation</strong>: Recent developments enable generation of arbitrary-length sequences through semi-autoregressive approaches<sup id="fnref:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup> <sup id="fnref1:17"><a href="#fn:17" class="footnote-ref" role="doc-noteref">17</a></sup>.</p>
<h2 id="simple-pytorch-implementation">Simple PyTorch Implementation<a hidden class="anchor" aria-hidden="true" href="#simple-pytorch-implementation">#</a></h2>
<p>Here&rsquo;s a basic implementation of a masked diffusion language model in PyTorch:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch.nn <span style="color:#66d9ef">as</span> nn
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch.nn.functional <span style="color:#66d9ef">as</span> F
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> math
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">MaskedDiffusionLM</span>(nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    A simple masked diffusion language model implementation.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    Based on the MDLM framework with absorbing state diffusion.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, vocab_size, d_model<span style="color:#f92672">=</span><span style="color:#ae81ff">512</span>, n_heads<span style="color:#f92672">=</span><span style="color:#ae81ff">8</span>, n_layers<span style="color:#f92672">=</span><span style="color:#ae81ff">6</span>, max_len<span style="color:#f92672">=</span><span style="color:#ae81ff">1024</span>):
</span></span><span style="display:flex;"><span>        super()<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>vocab_size <span style="color:#f92672">=</span> vocab_size
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>d_model <span style="color:#f92672">=</span> d_model
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>max_len <span style="color:#f92672">=</span> max_len
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>mask_token_id <span style="color:#f92672">=</span> vocab_size <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>  <span style="color:#75715e"># Reserve last token as mask</span>
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Token and position embeddings</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>token_embedding <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Embedding(vocab_size, d_model)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>pos_embedding <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Embedding(max_len, d_model)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Time embedding for diffusion timestep</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>time_embedding <span style="color:#f92672">=</span> TimeEmbedding(d_model)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Transformer layers</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>transformer_layers <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>ModuleList([
</span></span><span style="display:flex;"><span>            TransformerBlock(d_model, n_heads) <span style="color:#66d9ef">for</span> _ <span style="color:#f92672">in</span> range(n_layers)
</span></span><span style="display:flex;"><span>        ])
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Output projection</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>output_proj <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Linear(d_model, vocab_size)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>layer_norm <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>LayerNorm(d_model)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x, t):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Forward pass for training.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Args:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            x: Token sequences [batch_size, seq_len]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            t: Diffusion timesteps [batch_size]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        batch_size, seq_len <span style="color:#f92672">=</span> x<span style="color:#f92672">.</span>shape
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Token embeddings</span>
</span></span><span style="display:flex;"><span>        token_emb <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>token_embedding(x)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Position embeddings</span>
</span></span><span style="display:flex;"><span>        positions <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>arange(seq_len, device<span style="color:#f92672">=</span>x<span style="color:#f92672">.</span>device)<span style="color:#f92672">.</span>unsqueeze(<span style="color:#ae81ff">0</span>)<span style="color:#f92672">.</span>expand(batch_size, <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>        pos_emb <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>pos_embedding(positions)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Time embeddings</span>
</span></span><span style="display:flex;"><span>        time_emb <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>time_embedding(t)  <span style="color:#75715e"># [batch_size, d_model]</span>
</span></span><span style="display:flex;"><span>        time_emb <span style="color:#f92672">=</span> time_emb<span style="color:#f92672">.</span>unsqueeze(<span style="color:#ae81ff">1</span>)<span style="color:#f92672">.</span>expand(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, seq_len, <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Combine embeddings</span>
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> token_emb <span style="color:#f92672">+</span> pos_emb <span style="color:#f92672">+</span> time_emb
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Apply transformer layers</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> layer <span style="color:#f92672">in</span> self<span style="color:#f92672">.</span>transformer_layers:
</span></span><span style="display:flex;"><span>            x <span style="color:#f92672">=</span> layer(x)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>layer_norm(x)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Output logits</span>
</span></span><span style="display:flex;"><span>        logits <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>output_proj(x)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> logits
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">TimeEmbedding</span>(nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;Sinusoidal time embedding for diffusion timesteps.&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, d_model):
</span></span><span style="display:flex;"><span>        super()<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>d_model <span style="color:#f92672">=</span> d_model
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, t):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Args:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            t: Timesteps [batch_size]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Returns:
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">            Time embeddings [batch_size, d_model]
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        half_dim <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>d_model <span style="color:#f92672">//</span> <span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>        emb <span style="color:#f92672">=</span> math<span style="color:#f92672">.</span>log(<span style="color:#ae81ff">10000</span>) <span style="color:#f92672">/</span> (half_dim <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>        emb <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>exp(torch<span style="color:#f92672">.</span>arange(half_dim, device<span style="color:#f92672">=</span>t<span style="color:#f92672">.</span>device) <span style="color:#f92672">*</span> <span style="color:#f92672">-</span>emb)
</span></span><span style="display:flex;"><span>        emb <span style="color:#f92672">=</span> t[:, <span style="color:#66d9ef">None</span>] <span style="color:#f92672">*</span> emb[<span style="color:#66d9ef">None</span>, :]
</span></span><span style="display:flex;"><span>        emb <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>cat([emb<span style="color:#f92672">.</span>sin(), emb<span style="color:#f92672">.</span>cos()], dim<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> emb
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">TransformerBlock</span>(nn<span style="color:#f92672">.</span>Module):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;Standard transformer block with self-attention and feed-forward.&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, d_model, n_heads):
</span></span><span style="display:flex;"><span>        super()<span style="color:#f92672">.</span>__init__()
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>attention <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>MultiheadAttention(d_model, n_heads, batch_first<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>norm1 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>LayerNorm(d_model)
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>norm2 <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>LayerNorm(d_model)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>feed_forward <span style="color:#f92672">=</span> nn<span style="color:#f92672">.</span>Sequential(
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Linear(d_model, <span style="color:#ae81ff">4</span> <span style="color:#f92672">*</span> d_model),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>GELU(),
</span></span><span style="display:flex;"><span>            nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">4</span> <span style="color:#f92672">*</span> d_model, d_model)
</span></span><span style="display:flex;"><span>        )
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">forward</span>(self, x):
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Self-attention with residual connection</span>
</span></span><span style="display:flex;"><span>        attn_out, _ <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>attention(x, x, x)
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>norm1(x <span style="color:#f92672">+</span> attn_out)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Feed-forward with residual connection</span>
</span></span><span style="display:flex;"><span>        ff_out <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>feed_forward(x)
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>norm2(x <span style="color:#f92672">+</span> ff_out)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> x
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">DiffusionTrainer</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;Training utilities for masked diffusion language model.&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, model, vocab_size):
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>model <span style="color:#f92672">=</span> model
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>vocab_size <span style="color:#f92672">=</span> vocab_size
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>mask_token_id <span style="color:#f92672">=</span> vocab_size <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">q_sample</span>(self, x_0, t):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Sample from q(x_t | x_0) - the forward diffusion process.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Implements absorbing state diffusion with masking.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        batch_size, seq_len <span style="color:#f92672">=</span> x_0<span style="color:#f92672">.</span>shape
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Compute noise schedule (linear for simplicity)</span>
</span></span><span style="display:flex;"><span>        alpha_t <span style="color:#f92672">=</span> <span style="color:#ae81ff">1.0</span> <span style="color:#f92672">-</span> t<span style="color:#f92672">.</span>float() <span style="color:#f92672">/</span> <span style="color:#ae81ff">1000.0</span>  <span style="color:#75715e"># Assume 1000 timesteps</span>
</span></span><span style="display:flex;"><span>        alpha_t <span style="color:#f92672">=</span> alpha_t<span style="color:#f92672">.</span>clamp(<span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">0.99</span>)  <span style="color:#75715e"># Avoid complete masking</span>
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Create mask probabilities</span>
</span></span><span style="display:flex;"><span>        mask_prob <span style="color:#f92672">=</span> (<span style="color:#ae81ff">1</span> <span style="color:#f92672">-</span> alpha_t)<span style="color:#f92672">.</span>unsqueeze(<span style="color:#ae81ff">1</span>)<span style="color:#f92672">.</span>expand(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, seq_len)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Sample which tokens to mask</span>
</span></span><span style="display:flex;"><span>        should_mask <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>rand_like(mask_prob) <span style="color:#f92672">&lt;</span> mask_prob
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Apply masking</span>
</span></span><span style="display:flex;"><span>        x_t <span style="color:#f92672">=</span> x_0<span style="color:#f92672">.</span>clone()
</span></span><span style="display:flex;"><span>        x_t[should_mask] <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>mask_token_id
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> x_t, should_mask
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">compute_loss</span>(self, x_0, model_output, mask):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Compute the simplified MDLM loss.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        This is a mixture of masked language modeling losses.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Only compute loss on masked positions</span>
</span></span><span style="display:flex;"><span>        masked_positions <span style="color:#f92672">=</span> mask
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> masked_positions<span style="color:#f92672">.</span>sum() <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> torch<span style="color:#f92672">.</span>tensor(<span style="color:#ae81ff">0.0</span>, device<span style="color:#f92672">=</span>x_0<span style="color:#f92672">.</span>device)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Extract predictions and targets for masked positions</span>
</span></span><span style="display:flex;"><span>        predictions <span style="color:#f92672">=</span> model_output[masked_positions]
</span></span><span style="display:flex;"><span>        targets <span style="color:#f92672">=</span> x_0[masked_positions]
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Compute cross-entropy loss</span>
</span></span><span style="display:flex;"><span>        loss <span style="color:#f92672">=</span> F<span style="color:#f92672">.</span>cross_entropy(predictions, targets)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> loss
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">training_step</span>(self, batch, optimizer):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;Single training step.&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        x_0 <span style="color:#f92672">=</span> batch  <span style="color:#75715e"># Clean text tokens</span>
</span></span><span style="display:flex;"><span>        batch_size <span style="color:#f92672">=</span> x_0<span style="color:#f92672">.</span>shape[<span style="color:#f92672">^</span><span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Sample random timesteps</span>
</span></span><span style="display:flex;"><span>        t <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>randint(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1000</span>, (batch_size,), device<span style="color:#f92672">=</span>x_0<span style="color:#f92672">.</span>device)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Forward diffusion: add noise</span>
</span></span><span style="display:flex;"><span>        x_t, mask <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>q_sample(x_0, t)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Model prediction</span>
</span></span><span style="display:flex;"><span>        logits <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>model(x_t, t)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Compute loss</span>
</span></span><span style="display:flex;"><span>        loss <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>compute_loss(x_0, logits, mask)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Backward pass</span>
</span></span><span style="display:flex;"><span>        optimizer<span style="color:#f92672">.</span>zero_grad()
</span></span><span style="display:flex;"><span>        loss<span style="color:#f92672">.</span>backward()
</span></span><span style="display:flex;"><span>        optimizer<span style="color:#f92672">.</span>step()
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> loss<span style="color:#f92672">.</span>item()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">DiffusionSampler</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;Sampling utilities for generating text.&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> __init__(self, model, vocab_size, num_timesteps<span style="color:#f92672">=</span><span style="color:#ae81ff">1000</span>):
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>model <span style="color:#f92672">=</span> model
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>vocab_size <span style="color:#f92672">=</span> vocab_size
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>mask_token_id <span style="color:#f92672">=</span> vocab_size <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>        self<span style="color:#f92672">.</span>num_timesteps <span style="color:#f92672">=</span> num_timesteps
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>    <span style="color:#a6e22e">@torch.no_grad</span>()
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">def</span> <span style="color:#a6e22e">sample</span>(self, batch_size, seq_len, device<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;cuda&#39;</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        Generate samples using the reverse diffusion process.
</span></span></span><span style="display:flex;"><span><span style="color:#e6db74">        &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Start with all masked tokens</span>
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>full((batch_size, seq_len), self<span style="color:#f92672">.</span>mask_token_id, 
</span></span><span style="display:flex;"><span>                      dtype<span style="color:#f92672">=</span>torch<span style="color:#f92672">.</span>long, device<span style="color:#f92672">=</span>device)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Reverse diffusion process</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> t <span style="color:#f92672">in</span> reversed(range(self<span style="color:#f92672">.</span>num_timesteps)):
</span></span><span style="display:flex;"><span>            t_batch <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>full((batch_size,), t, device<span style="color:#f92672">=</span>device)
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># Model prediction</span>
</span></span><span style="display:flex;"><span>            logits <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>model(x, t_batch)
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># Sample from the predicted distribution for masked positions</span>
</span></span><span style="display:flex;"><span>            mask_positions <span style="color:#f92672">=</span> (x <span style="color:#f92672">==</span> self<span style="color:#f92672">.</span>mask_token_id)
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> mask_positions<span style="color:#f92672">.</span>sum() <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">0</span>:
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># Sample new tokens for masked positions</span>
</span></span><span style="display:flex;"><span>                probs <span style="color:#f92672">=</span> F<span style="color:#f92672">.</span>softmax(logits[mask_positions], dim<span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># Avoid sampling the mask token</span>
</span></span><span style="display:flex;"><span>                probs[:, self<span style="color:#f92672">.</span>mask_token_id] <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>                probs <span style="color:#f92672">=</span> probs <span style="color:#f92672">/</span> probs<span style="color:#f92672">.</span>sum(dim<span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span>, keepdim<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>                
</span></span><span style="display:flex;"><span>                new_tokens <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>multinomial(probs, <span style="color:#ae81ff">1</span>)<span style="color:#f92672">.</span>squeeze(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>                x[mask_positions] <span style="color:#f92672">=</span> new_tokens
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> x
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Usage example</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">train_diffusion_model</span>():
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;Example training script.&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Model hyperparameters</span>
</span></span><span style="display:flex;"><span>    vocab_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">10000</span>  <span style="color:#75715e"># Including mask token</span>
</span></span><span style="display:flex;"><span>    d_model <span style="color:#f92672">=</span> <span style="color:#ae81ff">512</span>
</span></span><span style="display:flex;"><span>    n_heads <span style="color:#f92672">=</span> <span style="color:#ae81ff">8</span>
</span></span><span style="display:flex;"><span>    n_layers <span style="color:#f92672">=</span> <span style="color:#ae81ff">6</span>
</span></span><span style="display:flex;"><span>    max_len <span style="color:#f92672">=</span> <span style="color:#ae81ff">256</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Initialize model and trainer</span>
</span></span><span style="display:flex;"><span>    model <span style="color:#f92672">=</span> MaskedDiffusionLM(vocab_size, d_model, n_heads, n_layers, max_len)
</span></span><span style="display:flex;"><span>    trainer <span style="color:#f92672">=</span> DiffusionTrainer(model, vocab_size)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Optimizer</span>
</span></span><span style="display:flex;"><span>    optimizer <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>optim<span style="color:#f92672">.</span>AdamW(model<span style="color:#f92672">.</span>parameters(), lr<span style="color:#f92672">=</span><span style="color:#ae81ff">1e-4</span>)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Training loop (simplified)</span>
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">.</span>train()
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> epoch <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">10</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> batch_idx, batch <span style="color:#f92672">in</span> enumerate(dataloader):  <span style="color:#75715e"># Your data loader here</span>
</span></span><span style="display:flex;"><span>            loss <span style="color:#f92672">=</span> trainer<span style="color:#f92672">.</span>training_step(batch, optimizer)
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> batch_idx <span style="color:#f92672">%</span> <span style="color:#ae81ff">100</span> <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span>:
</span></span><span style="display:flex;"><span>                print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Epoch </span><span style="color:#e6db74">{</span>epoch<span style="color:#e6db74">}</span><span style="color:#e6db74">, Batch </span><span style="color:#e6db74">{</span>batch_idx<span style="color:#e6db74">}</span><span style="color:#e6db74">, Loss: </span><span style="color:#e6db74">{</span>loss<span style="color:#e6db74">:</span><span style="color:#e6db74">.4f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> model
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Generation example</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">generate_text</span>(model, vocab_size):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34;Example text generation.&#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    sampler <span style="color:#f92672">=</span> DiffusionSampler(model, vocab_size)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">.</span>eval()
</span></span><span style="display:flex;"><span>    samples <span style="color:#f92672">=</span> sampler<span style="color:#f92672">.</span>sample(batch_size<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span>, seq_len<span style="color:#f92672">=</span><span style="color:#ae81ff">128</span>, device<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;cuda&#39;</span>)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> samples
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> __name__ <span style="color:#f92672">==</span> <span style="color:#e6db74">&#34;__main__&#34;</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Train the model</span>
</span></span><span style="display:flex;"><span>    trained_model <span style="color:#f92672">=</span> train_diffusion_model()
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Generate samples</span>
</span></span><span style="display:flex;"><span>    generated_samples <span style="color:#f92672">=</span> generate_text(trained_model, vocab_size<span style="color:#f92672">=</span><span style="color:#ae81ff">10000</span>)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#34;Generated samples shape:&#34;</span>, generated_samples<span style="color:#f92672">.</span>shape)
</span></span></code></pre></div><h2 id="advanced-implementation-features">Advanced Implementation Features<a hidden class="anchor" aria-hidden="true" href="#advanced-implementation-features">#</a></h2>
<p>For production-ready implementations, several advanced features should be considered:</p>
<p><strong>Noise Scheduling</strong>: More sophisticated noise schedules like cosine or learned schedules can significantly improve performance<sup id="fnref:20"><a href="#fn:20" class="footnote-ref" role="doc-noteref">20</a></sup> <sup id="fnref2:8"><a href="#fn:8" class="footnote-ref" role="doc-noteref">8</a></sup>.</p>
<p><strong>Efficient Sampling</strong>: Techniques like cached sampling can provide 3-4x speedup over naive ancestral sampling<sup id="fnref:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup> <sup id="fnref:22"><a href="#fn:22" class="footnote-ref" role="doc-noteref">22</a></sup>.</p>
<p><strong>Semi-Autoregressive Generation</strong>: Extending generation to arbitrary lengths through stride-based approaches<sup id="fnref1:19"><a href="#fn:19" class="footnote-ref" role="doc-noteref">19</a></sup> <sup id="fnref1:21"><a href="#fn:21" class="footnote-ref" role="doc-noteref">21</a></sup>.</p>
<p><strong>Classifier-Free Guidance</strong>: Enabling controllable generation without explicit classifiers<sup id="fnref2:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup> <sup id="fnref:23"><a href="#fn:23" class="footnote-ref" role="doc-noteref">23</a></sup>.</p>
<h2 id="current-limitations-and-future-directions">Current Limitations and Future Directions<a hidden class="anchor" aria-hidden="true" href="#current-limitations-and-future-directions">#</a></h2>
<p>While diffusion language models show tremendous promise, they face several challenges. They typically exhibit slower inference than autoregressive models for short sequences, though this gap narrows for longer generations<sup id="fnref1:16"><a href="#fn:16" class="footnote-ref" role="doc-noteref">16</a></sup> <sup id="fnref:24"><a href="#fn:24" class="footnote-ref" role="doc-noteref">24</a></sup>. Training complexity remains higher than autoregressive approaches, and performance on complex reasoning tasks still lags behind state-of-the-art autoregressive models<sup id="fnref1:24"><a href="#fn:24" class="footnote-ref" role="doc-noteref">24</a></sup> <sup id="fnref:25"><a href="#fn:25" class="footnote-ref" role="doc-noteref">25</a></sup>.</p>
<p>However, recent developments suggest these limitations are surmountable engineering challenges rather than fundamental barriers. The emergence of hybrid architectures, scaling successes like LLaDA, and theoretical advances like SEDD position DLMs as a complementary and potentially superior approach for specific applications requiring sophisticated control, creativity, and bidirectional reasoning<sup id="fnref2:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup> <sup id="fnref3:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup> <sup id="fnref3:11"><a href="#fn:11" class="footnote-ref" role="doc-noteref">11</a></sup>.</p>
<p>The field stands at a critical juncture where continued investment could establish diffusion as the preferred paradigm for controllable, high-quality text generation, while hybrid approaches may ultimately combine the best aspects of both autoregressive and diffusion methods<sup id="fnref4:10"><a href="#fn:10" class="footnote-ref" role="doc-noteref">10</a></sup> <sup id="fnref:26"><a href="#fn:26" class="footnote-ref" role="doc-noteref">26</a></sup>. For practitioners and researchers, DLMs represent not just an alternative to current approaches, but a fundamentally different way of thinking about language generation that opens new possibilities for AI applications.</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p><a href="https://arxiv.org/abs/2406.07524">https://arxiv.org/abs/2406.07524</a>&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p><a href="https://arxiv.org/abs/2410.17891">https://arxiv.org/abs/2410.17891</a>&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:3">
<p><a href="https://assemblyai.com/blog/diffusion-models-for-machine-learning-introduction">https://assemblyai.com/blog/diffusion-models-for-machine-learning-introduction</a>&#160;<a href="#fnref:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:3" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:4">
<p><a href="https://lilianweng.github.io/posts/2021-07-11-diffusion-models/">https://lilianweng.github.io/posts/2021-07-11-diffusion-models/</a>&#160;<a href="#fnref:4" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:5">
<p><a href="https://papers.neurips.cc/paper/2021/file/958c530554f78bcd8e97125b70e6973d-Paper.pdf">https://papers.neurips.cc/paper/2021/file/958c530554f78bcd8e97125b70e6973d-Paper.pdf</a>&#160;<a href="#fnref:5" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:6">
<p><a href="https://openreview.net/forum?id=h7-XixPCAL">https://openreview.net/forum?id=h7-XixPCAL</a>&#160;<a href="#fnref:6" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:7">
<p><a href="https://s-sahoo.com/mdlm/">https://s-sahoo.com/mdlm/</a>&#160;<a href="#fnref:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:7" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:8">
<p><a href="https://openreview.net/pdf?id=L4uaAR4ArM">https://openreview.net/pdf?id=L4uaAR4ArM</a>&#160;<a href="#fnref:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:8" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:9">
<p><a href="https://theaisummer.com/diffusion-models/">https://theaisummer.com/diffusion-models/</a>&#160;<a href="#fnref:9" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:10">
<p><a href="https://huggingface.co/blog/ProCreations/diffusion-language-model">https://huggingface.co/blog/ProCreations/diffusion-language-model</a>&#160;<a href="#fnref:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref4:10" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:11">
<p><a href="https://ml-gsai.github.io/LLaDA-demo/">https://ml-gsai.github.io/LLaDA-demo/</a>&#160;<a href="#fnref:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref2:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref3:11" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:12">
<p><a href="https://arxiv.org/abs/2502.09992">https://arxiv.org/abs/2502.09992</a>&#160;<a href="#fnref:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:12" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:13">
<p><a href="https://www.semanticscholar.org/paper/ce806f8d32f6fb1eaa821248a1bc4fa2cd949fbb">https://www.semanticscholar.org/paper/ce806f8d32f6fb1eaa821248a1bc4fa2cd949fbb</a>&#160;<a href="#fnref:13" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:14">
<p><a href="https://arxiv.org/pdf/2310.16834.pdf">https://arxiv.org/pdf/2310.16834.pdf</a>&#160;<a href="#fnref:14" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:15">
<p><a href="https://arxiv.org/abs/2310.16834">https://arxiv.org/abs/2310.16834</a>&#160;<a href="#fnref:15" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:16">
<p><a href="https://www.seangoedecke.com/limitations-of-text-diffusion-models/">https://www.seangoedecke.com/limitations-of-text-diffusion-models/</a>&#160;<a href="#fnref:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:16" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:17">
<p><a href="https://arxiv.org/abs/2506.19037">https://arxiv.org/abs/2506.19037</a>&#160;<a href="#fnref:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:17" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:18">
<p><a href="https://arxiv.org/abs/2402.07754">https://arxiv.org/abs/2402.07754</a>&#160;<a href="#fnref:18" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:19">
<p><a href="https://arxiv.org/abs/2503.09573">https://arxiv.org/abs/2503.09573</a>&#160;<a href="#fnref:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:19" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:20">
<p><a href="https://arxiv.org/abs/2406.04329">https://arxiv.org/abs/2406.04329</a>&#160;<a href="#fnref:20" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:21">
<p><a href="https://github.com/kuleshov-group/mdlm">https://github.com/kuleshov-group/mdlm</a>&#160;<a href="#fnref:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:21" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:22">
<p><a href="https://openreview.net/forum?id=L4uaAR4ArM">https://openreview.net/forum?id=L4uaAR4ArM</a>&#160;<a href="#fnref:22" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:23">
<p><a href="https://arxiv.org/html/2408.04220v1">https://arxiv.org/html/2408.04220v1</a>&#160;<a href="#fnref:23" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:24">
<p><a href="https://arxiv.org/abs/2406.11473">https://arxiv.org/abs/2406.11473</a>&#160;<a href="#fnref:24" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a>&#160;<a href="#fnref1:24" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:25">
<p><a href="https://arxiv.org/abs/2409.02908">https://arxiv.org/abs/2409.02908</a>&#160;<a href="#fnref:25" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:26">
<p><a href="https://openreview.net/forum?id=j1tSLYKwg8">https://openreview.net/forum?id=j1tSLYKwg8</a>&#160;<a href="#fnref:26" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>

<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Diffusion Language Model on x"
            href="https://x.com/intent/tweet/?text=Diffusion%20Language%20Model&amp;url=https%3a%2f%2fsatani99.github.io%2fposts%2fdiffusion-language-model%2f&amp;hashtags=">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Diffusion Language Model on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fsatani99.github.io%2fposts%2fdiffusion-language-model%2f&amp;title=Diffusion%20Language%20Model&amp;summary=Diffusion%20Language%20Model&amp;source=https%3a%2f%2fsatani99.github.io%2fposts%2fdiffusion-language-model%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Diffusion Language Model on reddit"
            href="https://reddit.com/submit?url=https%3a%2f%2fsatani99.github.io%2fposts%2fdiffusion-language-model%2f&title=Diffusion%20Language%20Model">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Diffusion Language Model on facebook"
            href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fsatani99.github.io%2fposts%2fdiffusion-language-model%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Diffusion Language Model on whatsapp"
            href="https://api.whatsapp.com/send?text=Diffusion%20Language%20Model%20-%20https%3a%2f%2fsatani99.github.io%2fposts%2fdiffusion-language-model%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Diffusion Language Model on telegram"
            href="https://telegram.me/share/url?text=Diffusion%20Language%20Model&amp;url=https%3a%2f%2fsatani99.github.io%2fposts%2fdiffusion-language-model%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Diffusion Language Model on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=Diffusion%20Language%20Model&u=https%3a%2f%2fsatani99.github.io%2fposts%2fdiffusion-language-model%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://satani99.github.io/">Nikhil&#39;s blog</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
